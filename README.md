
# ELT Pipeline for TMDB-Pipeline-Recommendation

TMDB-Pipeline-Recommendation l√† m·ªôt d·ª± √°n thu·ªôc lƒ©nh v·ª±c Data Engineering, nh·∫±m x√¢y d·ª±ng m·ªôt h·ªá th·ªëng ELT pipeline x·ª≠ l√Ω d·ªØ li·ªáu h·ªó tr·ª£ cho:

     H·ªá th·ªëng g·ª£i √Ω phim d·ª±a tr√™n l·ªãch s·ª≠ ƒë√°nh gi√° phim c·ªßa c√° nh√¢n(Recommendation System)
     Dashboard ph√¢n t√≠ch v√† b√°o c√°o th√¥ng tin phim

D·ª± √°n t·∫≠p trung v√†o vi·ªác x√¢y d·ª±ng m·ªôt pipeline ELT ho√†n ch·ªânh, b·∫Øt ƒë·∫ßu t·ª´ vi·ªác thu th·∫≠p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn nh∆∞ Kaggle, TMDB API, Transform b·∫±ng Apache Spark theo ki·∫øn tr√∫c Lakehouse, l∆∞u tr·ªØ t·∫°i PostgreSQL, r·ªìi x√¢y d·ª±ng c√°c m√¥ h√¨nh d·ªØ li·ªáu v·ªõi DBT, v√† cu·ªëi c√πng l√† tr√¨nh b√†y d·ªØ li·ªáu qua giao di·ªán tr·ª±c quan b·∫±ng Streamlit. Dagster ƒë∆∞·ª£c l·ª±a ch·ªçn l√†m Data Orchestrater

  ## üöÄ C√°c c√¥ng ngh·ªá, ng√¥n ng·ªØ ch√≠nh ƒë∆∞·ª£c s·ª≠ d·ª•ng


‚öôÔ∏è Orchestration & Data Processing

  <p>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="60" style="margin-right: 50px;" title="Python" />
  <img src="images/spark.png" width="100" style="margin-right: 50px;" title="Apache Spark" />
  <img src="images/dagster.png" width="80" style="margin-right: 20px;" title="Dagster" />
  <img src="images/dbt.png" width="100" title="dbt" />
</p>




‚òÅÔ∏è L∆∞u tr·ªØ & Truy xu·∫•t d·ªØ li·ªáu
<p> <img src="https://min.io/resources/img/logo/MINIO_Bird.png" width="40" title="MinIO"/> 
<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/mysql/mysql-original.svg" width="40" title="MySQL"/>
<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/postgresql/postgresql-original.svg" width="40" title="PostgreSQL"/> 
  <img src="images/polar.png" width="80" title="Polars" />
<p> 

üìä Visualization
<p>
<img src="https://streamlit.io/images/brand/streamlit-logo-primary-colormark-darktext.svg" width="140" title="Streamlit"/> 
</p>
---

## Giao di·ªán Streamlit

![Giao di·ªán streamlit](images/output.jpg)  

## Project Overview




## 1. Data pipeline design 

![Pipeline Diagram](images/pipeline.png)  

**1. Data Sources ‚Äì Thu th·∫≠p d·ªØ li·ªáu**

  - D·ªØ li·ªáu phim ƒë∆∞·ª£c l·∫•y t·ª´ 2 ngu·ªìn ch√≠nh:

    - `TMDB API`: Tr√≠ch xu·∫•t th√¥ng tin phim t·ª´ API ch√≠nh th·ª©c c·ªßa The Movie Database (TMDB), bao g·ªìm c√°c b·ªô phim y√™u th√≠ch c·ªßa c√° nh√¢n.

    - `Kaggle`: Dataset(~1M) v·ªÅ th√¥ng tin phim c·ªßa TMDB

  - `MySQL`: D·ªØ li·ªáu th√¥, ch∆∞a qua x·ª≠ l√Ω ban ƒë·∫ßu(dataset kaggle 1M) ƒë∆∞·ª£c ƒë·∫©y v√†o MySQL

**2. Lakehouse ‚Äì X·ª≠ l√Ω v√† t·ªï ch·ª©c d·ªØ li·ªáu**
  - D·ªØ li·ªáu th√¥ ƒë∆∞·ª£c ƒë∆∞a v√†o h·ªá th·ªëng x·ª≠ l√Ω trung t√¢m s·ª≠ d·ª•ng:

      - `Apache Spark`: D√πng ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v·ªõi t·ªëc ƒë·ªô cao, theo ki·∫øn tr√∫c ƒëa t·∫ßng:

          - `Bronze`: L∆∞u tr·ªØ d·ªØ li·ªáu th√¥ ban ƒë·∫ßu sau khi ingest

          - `Silver`: L√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu

          - `Gold`: Enrich v√† t·ªï ch·ª©c d·ªØ li·ªáu ph·ª•c v·ª• ph√¢n t√≠ch v√† m√¥ h√¨nh

      - `Polars` S·ª≠ d·ª•ng trong m·ªôt s·ªë t√°c v·ª• ti·ªÅn x·ª≠ l√Ω/l√†m s·∫°ch d·ªØ li·ªáu hi·ªáu nƒÉng cao

      - `Spark MLlib`: √Åp d·ª•ng c√°c k·ªπ thu·∫≠t machine learning ƒë∆°n gi·∫£n ho·∫∑c g·ª£i √Ω d·ª±a tr√™n n·ªôi dung

**3. Warehouse ‚Äì L∆∞u tr·ªØ d·ªØ li·ªáu**
  - Sau khi x·ª≠ l√Ω qua c√°c t·∫ßng Bronze ‚Üí Silver ‚Üí Gold, d·ªØ li·ªáu ƒë∆∞·ª£c n·∫°p v√†o PostgreSQL nh∆∞ m·ªôt Data Warehouse.

    ƒê√¢y l√† n∆°i l∆∞u tr·ªØ d·ªØ li·ªáu ƒë√£ s·∫µn s√†ng cho ph√¢n t√≠ch, truy v·∫•n v√† ph·ª•c v·ª• c√°c ·ª©ng d·ª•ng ph√≠a ng∆∞·ªùi d√πng.

    `DBT` :  x√¢y d·ª±ng c√°c b·∫£ng trung gian (models)  ti·ªán cho truy v·∫•n c·ªßa Front-end

**4. Streamlit ‚Äì Giao di·ªán ng∆∞·ªùi d√πng**
  - S·ª≠ d·ª•ng `Streamlit` ƒë·ªÉ x√¢y d·ª±ng giao di·ªán tr·ª±c quan, bao g·ªìm 3 t√≠nh nƒÉng ch√≠nh:

    - `Recommendations`: H·ªá th·ªëng g·ª£i √Ω phim d·ª±a tr√™n h√†nh vi ho·∫∑c n·ªôi dung

    - `Visualizations`: Bi·ªÉu ƒë·ªì, dashboard v·ªÅ d·ªØ li·ªáu phim

    - `Search Information`: T√¨m ki·∫øm phim theo b·ªô l·ªçc(rating, genres, time)


        ---

## 2. Data lineage

 T√¥i s·ª≠ d·ª•ng **Dagster** ƒë·ªÉ orchestrator. Dagster l√† m·ªôt data orchestrator gi√∫p x√¢y d·ª±ng, qu·∫£n l√Ω v√† gi√°m s√°t c√°c pipeline x·ª≠ l√Ω d·ªØ li·ªáu


![Data lineage](images/lineage.jpg)  

**chia ti·∫øt t·ª´ng layer**



![bronze_layer](images/bronze_layer.jpg)  

![silver layer](images/silver.jpg)  

![gold layer](images/gold.jpg)  

![warehouse layer](images/warehouse.jpg)  

## 3..C√°c B∆∞·ªõc C√†i ƒê·∫∑t & Tri·ªÉn Khai

### Y√™u C·∫ßu Ban ƒê·∫ßu
- Docker<Docker Compose>
- DBvear ho·∫∑c m·ªôt c√¥ng c·ª• qu·∫£n l√Ω SQL (ƒë·ªÉ qu·∫£n l√Ω database cho PostgreSQL v√† MySQL)
- Python 3

### C√°c B∆∞·ªõc Tri·ªÉn Khai

1. **Clone Repository & C√†i ƒê·∫∑t D·ª± √Ån:**
    ```sh
    git clone <repository-url>
    cd <repository-folder>
    ```
2. **T·∫£i Dataset:**
   - T·∫£i dataset t·ª´ Kaggle ([Link t·∫£i dataset](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies)) v√† ƒë·∫∑t ch√∫ng v√†o th∆∞ m·ª•c `dataset`.

3. **Chu·∫©n B·ªã File ENV:**

   - ƒêi·ªÅn c√°c th√¥ng tin c·∫ßn thi·∫øt v√†o file [env](http://_vscodecontentref_/0):
     - **TMDB:** Truy c·∫≠p [TMDB](https://www.themoviedb.org/)
      Sau khi t·∫°o t√†i kho·∫£n, b·∫°n h√£y t·ª± ƒë√°nh gi√° 1 s·ªë phim v√† th√™m ch√∫ng v√†o danh m·ª•c phim y√™u th√≠ch.

      Sau ƒë√≥ b·∫°n v√†o Settings/API --> t·∫°i ƒë√¢y b·∫°n s·∫Ω l·∫•y ``API Access Token`` v√† ƒëi·ªÅn v√†o env

      ![API Access Token ](images/API.jpg)  
     
   *(B·∫°n c√≥ th·ªÉ t√πy ch·ªânh env ƒë·ªëi v·ªõi c√°c n·ªôi dung c√≤n l·∫°i )*

4. **Thi·∫øt L·∫≠p M√¥i Tr∆∞·ªùng ·∫¢o & Ki·ªÉm Tra Python:**
    ```sh
    python3 -V        # Ki·ªÉm tra phi√™n b·∫£n Python
    python3 -m venv venv  # T·∫°o m√¥i tr∆∞·ªùng ·∫£o
    source venv/bin/activate
    ```

5. **Bi√™n D·ªãch & X√¢y D·ª±ng C√°c Container Theo Th·ª© T·ª±:**
   - X√¢y d·ª±ng c√°c th√†nh ph·∫ßn ri√™ng l·∫ª (ƒë·ªçc chi ti·∫øt trong Makefile):
     ```sh
     make build-dagster
     make build-spark
     make build-pipeline
     make build-streamlit

     make build
     ```
   - Kh·ªüi ch·∫°y c√°c container:
     ```sh
     make up
     ```
   - Sau khi ch·∫°y, v√†o Docker Desktop ƒë·ªÉ ki·ªÉm tra ti·∫øn tr√¨nh container.  

---

## Load Dataset V√†o MySQL & PostgreSQL

### Load Dataset v√†o MySQL

1. **V√†o Container MySQL v·ªõi Quy·ªÅn Root:**
    ```sh
    make to_mysql_root
    ```
2. **Th·ª±c Hi·ªán C√°c L·ªánh C·∫•u H√¨nh:**
    ```sql
    SET GLOBAL local_infile=TRUE;
    SHOW VARIABLES LIKE "local_infile";
    exit
    ```
3. **Import D·ªØ Li·ªáu:**
    ```sh
    make to_mysql
    source /tmp/mysql_schemas.sql;
    show tables;
    source /tmp/load_dataset/mysql_load.sql;
    exit
    ```
4. **Ki·ªÉm Tra D·ªØ Li·ªáu Tr√™n DBveaver:**  
   K·∫øt n·ªëi v√† ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c upload l√™n MySQL.

### T·∫°o Database cho PostgreSQL

1. **V√†o Container PostgreSQL:**
    ```sh
    make to_psql
    ```
2. **Th·ª±c Hi·ªán L·ªánh T·∫°o Database:**
    ```sql
    source /tmp/load_dataset/psql_datasource.sql;
    ```
3. **Ki·ªÉm Tra D·ªØ Li·ªáu:**  
   T∆∞∆°ng t·ª± nh∆∞ MySQL, b·∫°n c≈©ng s·ª≠ d·ª•ng DBeaver ƒë·ªÉ k·∫øt n·ªëi PSQL v√† ki·ªÉm tra database

---

4. Ti·∫øp Theo: T·ª± ƒê·ªông H√≥a Job & Ch·∫°y C√°c Asset Qua Dagster

- Sau khi ho√†n th√†nh vi·ªác c√†i ƒë·∫∑t v√† import d·ªØ li·ªáu, h√£y v√†o giao di·ªán c·ªßa Dagster theo ƒë·ªãa ch·ªâ ƒë√£ c·∫•u h√¨nh (vd: `http://localhost:3001`) ƒë·ªÉ ki·ªÉm tra v√† ch·∫°y c√°c asset ELT.
- T·ª´ giao di·ªán Dagster, b·∫°n c√≥ th·ªÉ theo d√µi pipeline ELT, ch·∫°y th·ª≠ t·ª´ng asset, v√† xem log ƒë·ªÉ ƒë·∫£m b·∫£o qu√° tr√¨nh ELT ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng.

5. X√¢y d·ª±ng c√°c model truy c·∫•n b·∫±ng DBT 
- Sau khi ch·∫°y asset t·ªõi warehouse, b·∫°n ti·∫øp t·ª•c ch·∫°y th·ªß c√¥ng DBT b·∫±ng l·ªánh(ch·∫°y l·∫ßn l∆∞·ª£t)
    ```sh
        cd elt_pipeline/dbt_movies
        dbt debug
        dbt build
    ```
6. Truy c·∫≠p Streamlit ƒë·ªÉ kh√°m ph√° application
      ![API Access Token ](images/streamlit.jpg)  
---

## L·ªùi K·∫øt

ƒê√¢y l√† d·ª± √°n Data Pipeline th·ª© hai m√† m√¨nh th·ª±c hi·ªán, qua ƒë√≥ m√¨nh ƒë√£ c√≥ c∆° h·ªôi h·ªçc th√™m v√† √°p d·ª•ng c√°c c√¥ng ngh·ªá m·ªõi trong lƒ©nh v·ª±c Data Engineering.
M√¨nh hy v·ªçng r·∫±ng source code n√†y s·∫Ω tr·ªü th√†nh m·ªôt t√†i li·ªáu tham kh·∫£o h·ªØu √≠ch cho b·∫°n ‚Äì d√π ƒëang h·ªçc t·∫≠p hay l√†m vi·ªác ‚Äì tr√™n h√†nh tr√¨nh kh√°m ph√° v√† ph√°t tri·ªÉn trong lƒ©nh v·ª±c d·ªØ li·ªáu.

**Happy Coding!**